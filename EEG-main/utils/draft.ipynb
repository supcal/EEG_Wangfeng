{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18788/232888377.py:23: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  edges = pickle.load(f)\n",
      "/tmp/ipykernel_18788/232888377.py:23: DeprecationWarning: Please use `csc_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csc` namespace is deprecated.\n",
      "  edges = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_scatter import scatter_add\n",
    "def _norm(edge_index, num_nodes, edge_weight=None, improved=False, dtype=None):\n",
    "    if edge_weight is None:\n",
    "        edge_weight = torch.ones((edge_index.size(1), ),\n",
    "                                dtype=dtype,\n",
    "                                device=edge_index.device)\n",
    "    edge_weight = edge_weight.view(-1)\n",
    "    assert edge_weight.size(0) == edge_index.size(1)\n",
    "    row, col = edge_index.detach()\n",
    "    deg = scatter_add(edge_weight.clone(), row.clone(), dim=0, dim_size=num_nodes)                                                          \n",
    "    deg_inv_sqrt = deg.pow(-1)\n",
    "    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        \n",
    "    return deg_inv_sqrt, row, col\n",
    "\n",
    "from torch_geometric.utils import add_self_loops\n",
    "with open('./data/ACM/node_features.pkl','rb') as f:\n",
    "        node_features = pickle.load(f)\n",
    "with open('./data/ACM/edges.pkl','rb') as f:\n",
    "    edges = pickle.load(f)\n",
    "with open('./data/ACM/labels.pkl','rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = edges[0].shape[0]\n",
    "# build adjacency matrices for each edge type\n",
    "A = []\n",
    "for i,edge in enumerate(edges):\n",
    "    edge_tmp = torch.from_numpy(np.vstack((edge.nonzero()[1], edge.nonzero()[0]))).type(torch.cuda.LongTensor)\n",
    "    value_tmp = torch.ones(edge_tmp.shape[1]).type(torch.cuda.FloatTensor)\n",
    "    # normalize each adjacency matrix\n",
    "    edge_tmp, value_tmp = add_self_loops(edge_tmp, edge_attr=value_tmp, fill_value=1e-20, num_nodes=num_nodes)\n",
    "    deg_inv_sqrt, deg_row, deg_col = _norm(edge_tmp.detach(), num_nodes, value_tmp.detach())\n",
    "    value_tmp = deg_inv_sqrt[deg_row] * value_tmp\n",
    "    A.append((edge_tmp,value_tmp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_tmp = torch.stack((torch.arange(0,num_nodes),torch.arange(0,num_nodes))).type(torch.cuda.LongTensor)\n",
    "value_tmp = torch.ones(num_nodes).type(torch.cuda.FloatTensor)\n",
    "A.append((edge_tmp,value_tmp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[3025, 3026, 3027,  ..., 8991, 8992, 8993],\n",
      "        [   0,    0,    0,  ..., 8991, 8992, 8993]], device='cuda:0'), tensor([0.3333, 0.0588, 1.0000,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')), (tensor([[   0,  734, 3015,  ..., 8991, 8992, 8993],\n",
      "        [3025, 3025, 3025,  ..., 8991, 8992, 8993]], device='cuda:0'), tensor([0.3333, 0.3333, 0.2500,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')), (tensor([[8937, 8938, 8939,  ..., 8991, 8992, 8993],\n",
      "        [   0,    1,    2,  ..., 8991, 8992, 8993]], device='cuda:0'), tensor([2.0000e-01, 3.2787e-03, 8.4034e-04,  ..., 1.0000e-20, 1.0000e-20,\n",
      "        1.0000e-20], device='cuda:0')), (tensor([[   0,   75,  586,  ..., 8991, 8992, 8993],\n",
      "        [8937, 8937, 8937,  ..., 8991, 8992, 8993]], device='cuda:0'), tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')), (tensor([[   0,    1,    2,  ..., 8991, 8992, 8993],\n",
      "        [   0,    1,    2,  ..., 8991, 8992, 8993]], device='cuda:0'), tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'))]\n",
      "torch.Size([2, 18930])\n",
      "torch.Size([18930])\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "print(A[0][0].shape)\n",
    "print(A[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8994, 1902])\n"
     ]
    }
   ],
   "source": [
    "node_features = torch.from_numpy(node_features).type(torch.cuda.FloatTensor)\n",
    "print(node_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch_sparse\n",
    "\n",
    "weight = torch.Tensor(2,5)\n",
    "\n",
    "filter = F.softmax(weight, dim=1)   \n",
    "num_channels = filter.shape[0]\n",
    "results = []\n",
    "for i in range(num_channels):\n",
    "    for j, (edge_index,edge_value) in enumerate(A):\n",
    "        if j == 0:\n",
    "            total_edge_index = edge_index\n",
    "            total_edge_value = edge_value*filter[i][j]\n",
    "        else:\n",
    "            total_edge_index = torch.cat((total_edge_index, edge_index), dim=1)\n",
    "            total_edge_value = torch.cat((total_edge_value, edge_value*filter[i][j]))\n",
    "    \n",
    "    index, value = torch_sparse.coalesce(total_edge_index.detach(), total_edge_value, m=num_nodes, n=num_nodes, op='add')\n",
    "    results.append((index, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[   0,    0,    0,  ..., 8992, 8993, 8993],\n",
      "        [   0, 3025, 3026,  ..., 8992, 3014, 8993]], device='cuda:0'), tensor([0.6000, 0.0667, 0.0667,  ..., 0.8000, 0.2000, 0.8000], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/external/wf/dataset/seed\n"
     ]
    }
   ],
   "source": [
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "filename=\"/home/wf/EEG_GTN/utils/data.config\"\n",
    "config.read(filename,encoding='UTF-8') \n",
    "print(config['path']['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_nums = [i for i in range(40*7)]\n",
    "length=7\n",
    "for i in range(40):\n",
    "    exp_test = exp_nums[i*length:i*length+length]\n",
    "    exp_train = [x for x in exp_nums if x not in exp_test]\n",
    "    print(exp_test,exp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data=torch.load(\"/home/wf/EEG_GTN/data/dataset/SEED/features_zero/seed_dcau_lds_zero/data.pt\")\n",
    "label=torch.load(\"/home/wf/EEG_GTN/data/dataset/SEED/features_zero/seed_dcau_lds_zero/label.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 3, 15, 23, 265, 5])\n",
      "torch.Size([15, 3, 15])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root = \"/home/wf/EEG_GTN/data/dataset/Processed_Dataset/seed_iv\"\n",
    "\n",
    "features=['de','psd','dasm','dcau','rasm']\n",
    "\n",
    "for feature in features:\n",
    "    if not os.path.exists(os.path.join(root, feature)):\n",
    "        os.makedirs(os.path.join(root, feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'de_movingAve1', 'de_LDS1', 'psd_movingAve1', 'psd_LDS1', 'de_movingAve2', 'de_LDS2', 'psd_movingAve2', 'psd_LDS2', 'de_movingAve3', 'de_LDS3', 'psd_movingAve3', 'psd_LDS3', 'de_movingAve4', 'de_LDS4', 'psd_movingAve4', 'psd_LDS4', 'de_movingAve5', 'de_LDS5', 'psd_movingAve5', 'psd_LDS5', 'de_movingAve6', 'de_LDS6', 'psd_movingAve6', 'psd_LDS6', 'de_movingAve7', 'de_LDS7', 'psd_movingAve7', 'psd_LDS7', 'de_movingAve8', 'de_LDS8', 'psd_movingAve8', 'psd_LDS8', 'de_movingAve9', 'de_LDS9', 'psd_movingAve9', 'psd_LDS9', 'de_movingAve10', 'de_LDS10', 'psd_movingAve10', 'psd_LDS10', 'de_movingAve11', 'de_LDS11', 'psd_movingAve11', 'psd_LDS11', 'de_movingAve12', 'de_LDS12', 'psd_movingAve12', 'psd_LDS12', 'de_movingAve13', 'de_LDS13', 'psd_movingAve13', 'psd_LDS13', 'de_movingAve14', 'de_LDS14', 'psd_movingAve14', 'psd_LDS14', 'de_movingAve15', 'de_LDS15', 'psd_movingAve15', 'psd_LDS15', 'de_movingAve16', 'de_LDS16', 'psd_movingAve16', 'psd_LDS16', 'de_movingAve17', 'de_LDS17', 'psd_movingAve17', 'psd_LDS17', 'de_movingAve18', 'de_LDS18', 'psd_movingAve18', 'psd_LDS18', 'de_movingAve19', 'de_LDS19', 'psd_movingAve19', 'psd_LDS19', 'de_movingAve20', 'de_LDS20', 'psd_movingAve20', 'psd_LDS20', 'de_movingAve21', 'de_LDS21', 'psd_movingAve21', 'psd_LDS21', 'de_movingAve22', 'de_LDS22', 'psd_movingAve22', 'psd_LDS22', 'de_movingAve23', 'de_LDS23', 'psd_movingAve23', 'psd_LDS23', 'de_movingAve24', 'de_LDS24', 'psd_movingAve24', 'psd_LDS24'])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sci\n",
    "\n",
    "data=sci.loadmat(\"/home/wf/EEG_GTN/data/dataset/SEED_IV/eeg_feature_smooth/1/01.mat\")\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#coding=utf-8\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Modified_SPPLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_levels, pool_type='max_pool'):\n",
    "        super(Modified_SPPLayer, self).__init__()\n",
    "\n",
    "        self.num_levels = num_levels\n",
    "        self.pool_type = pool_type\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # num:样本数量 c:通道数 h:高 w:宽\n",
    "        # num: the number of samples\n",
    "        # c: the number of channels\n",
    "        # h: height\n",
    "        # w: width\n",
    "        num, c, h, w = x.size() \n",
    "#         print(x.size())\n",
    "        for i in range(self.num_levels):\n",
    "            level = math.pow(2,i)\n",
    "\n",
    "            '''\n",
    "            The equation is explained on the following site:\n",
    "            http://www.cnblogs.com/marsggbo/p/8572846.html#autoid-0-0-0\n",
    "            '''\n",
    "            kernel_size = (math.ceil(h / level), math.ceil(w / level))\n",
    "            stride = (math.floor(h / level), math.floor(w / level))\n",
    "            pooling = (math.floor((kernel_size[0]*level-h+1)/2), math.floor((kernel_size[1]*level-w+1)/2))\n",
    "            \n",
    "            # update input data with padding\n",
    "            zero_pad = torch.nn.ZeroPad2d((pooling[1],pooling[1],pooling[0],pooling[0]))\n",
    "            x_new = zero_pad(x)\n",
    "            \n",
    "            # update kernel and stride\n",
    "            h_new = 2*pooling[0] + h\n",
    "            w_new = 2*pooling[1] + w\n",
    "            \n",
    "            kernel_size = (math.ceil(h_new / level), math.ceil(w_new / level))\n",
    "            stride = (math.floor(h_new / level), math.floor(w_new / level))\n",
    "            \n",
    "            \n",
    "            # 选择池化方式 \n",
    "            if self.pool_type == 'max_pool':\n",
    "                try:\n",
    "                    tensor = F.max_pool2d(x_new, kernel_size=kernel_size, stride=stride).view(num, -1)\n",
    "                except Exception as e:\n",
    "                    print(str(e))\n",
    "                    print(x.size())\n",
    "                    print(level)\n",
    "            else:\n",
    "                tensor = F.avg_pool2d(x_new, kernel_size=kernel_size, stride=stride).view(num, -1)\n",
    "            \n",
    "            \n",
    "              \n",
    "            # 展开、拼接\n",
    "            if (i == 0):\n",
    "                x_flatten = tensor.view(num, -1)\n",
    "            else:\n",
    "                x_flatten = torch.cat((x_flatten, tensor.view(num, -1)), 1)\n",
    "        return x_flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 210])\n"
     ]
    }
   ],
   "source": [
    "spp=Modified_SPPLayer(3)\n",
    "\n",
    "x=torch.rand(12,10,10,10)\n",
    "print(spp.forward(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "file_path = '/home/wf/EEG_GTN/data/dataset/SEED/channel-order.xlsx' \n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "data.columns = ['Electrode', 'X', 'Y', 'Z']\n",
    "coordinates = data[['X', 'Y', 'Z']].values\n",
    "\n",
    "distance_matrix = squareform(pdist(coordinates))\n",
    "\n",
    "distance_df = pd.DataFrame(distance_matrix, columns=data['Electrode'], index=data['Electrode'])\n",
    "\n",
    "theta = 1 \n",
    "tau = 0.05\n",
    "\n",
    "def gaussian_kernel(distance, theta, tau):\n",
    "    if distance <= tau:\n",
    "        return np.exp(-(distance ** 2) / (2 * theta ** 2))\n",
    "    else:\n",
    "        return 1e-10\n",
    "\n",
    "adjacency_matrix = distance_df.applymap(lambda x: gaussian_kernel(x, theta, tau))\n",
    "\n",
    "import torch\n",
    "torch.save(torch.from_numpy(adjacency_matrix.values).float(), \"/home/wf/EEG_GTN/data/dataset/SEED/adjacency_matrix.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load(\"/root/EEG_GTN/data/dataset/Processed_Dataset/faced/zero/psd/data.pt\")\n",
    "label = torch.load(\"/root/EEG_GTN/data/dataset/Processed_Dataset/faced/zero/psd/label.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([123, 1, 28, 32, 30, 5]) torch.Size([123, 1, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape,label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([123, 1, 12, 32, 30, 5]) torch.Size([123, 1, 12])\n",
      "torch.Size([123, 1, 12, 32, 30, 5]) torch.Size([123, 1, 12])\n"
     ]
    }
   ],
   "source": [
    "data1 = data[:,:,:12,:,:,:]\n",
    "data2 = data[:,:,16:,:,:,:]\n",
    "\n",
    "label1 = label[:,:,:12]\n",
    "label2 = label[:,:,16:]\n",
    "print(data1.shape,label1.shape)\n",
    "print(data2.shape,label2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([123, 1, 24, 32, 30, 5]) torch.Size([123, 1, 24])\n"
     ]
    }
   ],
   "source": [
    "data_new = torch.cat([data1,data2],dim=2)\n",
    "label_new = torch.cat([label1,label2],dim=2)\n",
    "print(data_new.shape,label_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data_new,\"/root/EEG_GTN/data/dataset/Processed_Dataset/faced/2class/psd/data.pt\")\n",
    "torch.save(label_new,\"/root/EEG_GTN/data/dataset/Processed_Dataset/faced/2class/psd/label.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "label = torch.load(\"/root/EEG_GTN/data/dataset/Processed_Dataset/faced/2class/de/label.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 2., 2., 2.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 2., 2., 2.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 2., 2., 2.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 2., 2., 2.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 2., 2., 2.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 2., 2., 2.]]])\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[label == 2.] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(label,\"/root/EEG_GTN/data/dataset/Processed_Dataset/faced/2class/de/label.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 4)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sci\n",
    "\n",
    "data = sci.loadmat(\n",
    "    \"/home/wf/EEG_GTN/data/dataset/DEAP/data_preprocessed/s01.mat\")\n",
    "print(data['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import os \n",
    "\n",
    "datapath = '/home/wf/EEG_GTN/data/dataset/DEAP/data_preprocessed'  # 数据路径\n",
    "datapaths = os.listdir(datapath)  # 获取数据路径下的所有文件\n",
    "datapaths.sort()  # 对文件名进行排序\n",
    "label = torch.zeros(32, 1, 40, 4)\n",
    "\n",
    "for idx, sub in enumerate(datapaths):\n",
    "\n",
    "    f = open(os.path.join(datapath, sub), 'rb')\n",
    "\n",
    "    data_sub = sio.loadmat(f)['labels']\n",
    "\n",
    "    label[idx, 0] = torch.from_numpy(data_sub)\n",
    "\n",
    "save_dir = os.path.join(\n",
    "    \"/home/wf/EEG_GTN/data/dataset/Processed_Dataset/deap/de\")\n",
    "torch.save(label, os.path.join(save_dir, \"label.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
